{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VIII_ArtificialNeuralNetwork_Load.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkQ0XKZkFCUn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "outputId": "790e17c8-8ffb-458d-c0a8-cd46f9d1c18e"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from fuzzywuzzy import fuzz\n",
        "from gensim.models import KeyedVectors\n",
        "from scipy.stats import skew, kurtosis\n",
        "from scipy.spatial.distance import cosine, cityblock, jaccard, canberra, euclidean, minkowski, braycurtis\n",
        "\n",
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lB8BP1_IwE4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "65ab823b-5320-4d6a-b2bc-4e6b6cf53037"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQAmLkJQGZQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "classifier = pickle.load(open('ANN.model', 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WgNaZnqGywx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "6a0aed75-0e99-4121-b169-f55d35c1de33"
      },
      "source": [
        "classifier.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_8 (Dense)              (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 8)                 72        \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 8)                 72        \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 8)                 72        \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 8)                 72        \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 8)                 72        \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 505\n",
            "Trainable params: 505\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pgf2jejuILhr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def wordmoverdistance(s1, s2):\n",
        "    s1 = str(s1).lower().split()\n",
        "    s2 = str(s2).lower().split()\n",
        "    s1 = [lemmatizer.lemmatize(w) for w in s1 if w not in stopwords.words('english')]\n",
        "    s2 = [lemmatizer.lemmatize(w) for w in s2 if w not in stopwords.words('english')]\n",
        "    return model.wmdistance(s1, s2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOo2YBmII3I9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sent2vec(s):\n",
        "    words = str(s).lower()\n",
        "    words = word_tokenize(words)\n",
        "    words = [w for w in words if not w in stopwords.words('english')]\n",
        "    words = [w for w in words if w.isalpha()]\n",
        "    M = []\n",
        "    for w in words:\n",
        "        try:\n",
        "            M.append(model[w])\n",
        "        except:\n",
        "            continue\n",
        "    M = np.array(M)\n",
        "    v = M.sum(axis=0)\n",
        "    return v / np.sqrt((v ** 2).sum())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUyuskEhN8Sz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_Scaler = pickle.load(open('XScaler','rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1TY-02fI7Rp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = KeyedVectors.load_word2vec_format('drive/My Drive/semantic-question-matching/GoogleNews-vectors-negative300.bin.gz', binary=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byJeocAlHRNM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#question1 = 'What practical applications might evolve from the discovery of the Higgs Boson ?'\n",
        "#question2 = 'What are some practical benefits of discovery of the Higgs Boson ?'\n",
        "\n",
        "question1 = 'How can I start an online shopping (e-commerce) website ?'\n",
        "question2 = 'Which web technology is best suitable for building a big E-Commerce website ?'\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uHg-grZIIP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "diff_len = len(str(question1)) - len(str(question2))\n",
        "common_words = len(set(str(question1).lower().split()).intersection(set(str(question2).lower().split())))\n",
        "fuzz_qratio = fuzz.QRatio(str(question1), str(question2))\n",
        "fuzz_WRatio = fuzz.WRatio(str(question1), str(question2))\n",
        "fuzz_partial_ratio = fuzz.partial_ratio(str(question1), str(question2))\n",
        "fuzz_partial_token_set_ratio = fuzz.partial_token_set_ratio(str(question1), str(question2))\n",
        "fuzz_partial_token_sort_ratio = fuzz.partial_token_sort_ratio(str(question1), str(question2))\n",
        "fuzz_token_set_ratio = fuzz.token_set_ratio(str(question1), str(question2))\n",
        "fuzz_token_sort_ratio = fuzz.token_sort_ratio(str(question1), str(question2))\n",
        "wmd = wordmoverdistance(question1, question2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRkdGcmkLlc_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "question1_vectors = sent2vec(question1)\n",
        "question2_vectors = sent2vec(question2)\n",
        "\n",
        "cosine_distance = cosine(question1_vectors, question2_vectors)\n",
        "\n",
        "cityblock_distance = cityblock(question1_vectors, question2_vectors)\n",
        "\n",
        "canberra_distance = canberra(question1_vectors, question2_vectors)\n",
        "\n",
        "euclidean_distance = euclidean(question1_vectors, question2_vectors)\n",
        "\n",
        "minkowski_distance = minkowski(question1_vectors, question2_vectors, 3)\n",
        "\n",
        "braycurtis_distance = braycurtis(question1_vectors, question2_vectors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLJOsx4BNP0o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "outputId": "d34252d2-03bc-4469-e00c-8af980d29863"
      },
      "source": [
        "X = np.array([diff_len, common_words, fuzz_qratio, fuzz_WRatio, fuzz_partial_ratio, fuzz_partial_token_set_ratio, \n",
        "             fuzz_partial_token_sort_ratio, fuzz_token_set_ratio, fuzz_token_sort_ratio, wmd, cosine_distance,\n",
        "             cityblock_distance, canberra_distance, euclidean_distance, minkowski_distance, braycurtis_distance\n",
        "             ])\n",
        "print(X)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-20.           2.          60.          60.          58.\n",
            " 100.          60.          55.          53.           2.59372402\n",
            "   0.38819116  12.29121685 156.39157534   0.88112557   0.39143173\n",
            "   0.49061381]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9Wf4hsHPP_C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = X_Scaler.transform(X.reshape(1,-1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVLUv3fDPzLY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "outputId": "201cfdef-551d-4009-a45e-39a2b1de9701"
      },
      "source": [
        "X"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.44513407,  1.09804822,  0.44057859,  0.16956127,  0.00825133,\n",
              "         0.20255278,  0.18230737,  0.54504029,  0.47123678, -0.31154066,\n",
              "        -0.542105  , -0.30564021, -0.0391188 , -0.33920903, -0.34273853,\n",
              "        -0.35185591]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mq0sOnwrP0yj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "8666b66d-c697-473a-f5bc-beaee7cf349c"
      },
      "source": [
        "y_pred = classifier.predict(X)\n",
        "print(y_pred)\n",
        "print(y_pred > 0.5)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.27985862]]\n",
            "[[False]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}